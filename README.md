# News Validator - Detecting Facts on the Ground Using Machine Learning  
**Task 2: Data Validation Team**

Welcome to my repository, part of the **GDSC PUP Manila** project titled **"Detecting Facts on the Ground Using Machine Learning"**. This repository showcases my work on data validation, ensuring the accuracy, reliability, and relevance of the data used throughout the project.

## üõ† Project Overview
As a member of the **Task 2: News Validator Team**, I contributed to the validation of data used to detect factual information from news articles. Our goal was to leverage **machine learning** to identify and filter out garbage data such as non-news content, duplicates, and null values from our dataset.

## üß© Responsibilities & Contributions
In this repository, you will find my contributions toward maintaining data quality and reliability throughout the project. Here's a summary of the specific tasks I undertook:

- **Data Validation:**  
  Ensured the **accuracy** and **relevance** of the collected data by validating news sources and filtering out unrelated or unreliable content.
  
- **Python Libraries Utilization:**  
  Utilized various **Python libraries** such as `pandas` and `numpy` to handle data manipulation and preprocessing efficiently.

- **Data Quality Checks:**  
  Conducted **data quality checks**, filtering out incorrect or incomplete data before further processing.

- **Non-News Content Filtering:**  
  Implemented techniques to detect and eliminate **non-news content** and tagged irrelevant information to ensure that the final dataset was clean.

## üîÑ Validation Workflow
The validation process followed in this project involved six key stages to ensure that the dataset was reliable and ready for machine learning tasks. Below is the visual representation of the **Validation Workflow**:

| Step | Task      | Description                                                                 |
|------|-----------|-----------------------------------------------------------------------------|
| 1    | **Import** | Import data in a preferred notebook environment.                             |
| 2    | **Explore**| Explore the dataset using Pandas or other Python libraries.                  |
| 3    | **Drop**   | Drop all duplicates, null values, and non-news data.                         |
| 4    | **Add**    | Add important features if needed.                                           |
| 5    | **Document**| Provide feedback, communicate with other teams, and create documentation.  |
| 6    | **Export** | Export the data and hand it over to the pre-processing team.                 |

## üìÅ Repository Contents
The repository is structured to include my work on data validation and preprocessing tasks:

- **`validation_scripts/`**  
  Contains Python scripts used for data validation and filtering tasks.

- **`reports/`**  
  Includes reports detailing validation processes, techniques, and results of data quality checks.
